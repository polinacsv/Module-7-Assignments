{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54d5436-a103-4743-8731-13e8510a2d94",
   "metadata": {
    "id": "c54d5436-a103-4743-8731-13e8510a2d94"
   },
   "source": [
    "## Homework 9: Text Classification with Fine-Tuned BERT\n",
    "\n",
    "### Due: Midnight on November 5th (with 2-hour grace period) — Worth 85 points\n",
    "\n",
    "In this final homework, we’ll explore **fine-tuning a pre-trained Transformer model (BERT)** for text classification using the **IMDB Movie Review** dataset. You’ll begin with a working baseline notebook and then conduct a series of controlled experiments to understand how data size, context length, and model architecture affect performance.\n",
    "\n",
    "You’ll complete three problems:\n",
    "\n",
    "* **Problem 1:** Evaluate how **sequence length** and **learning rate** jointly influence validation loss and generalization.\n",
    "* **Problem 2:** Measure how **training data size** affects both model performance and total training time.\n",
    "* **Problem 3:** Compare **two additional models** from the BERT family to analyze the trade-offs between model size and accuracy on this dataset.\n",
    "\n",
    "In each problem, you’ll report your key metrics, summarize what you observed, and reflect on what you learned.\n",
    "\n",
    "> **Note:** This homework was developed and tested on **Google Colab**, due to version conflicts when running locally. It is **strongly recommended** that you complete your work on Colab as well.\n",
    "\n",
    "There are 6 problems, each worth 14 points, and you get one point free if you complete the entire homework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "S-zVZFxlTWxP",
   "metadata": {
    "id": "S-zVZFxlTWxP"
   },
   "outputs": [],
   "source": [
    "# Install once per new Colab runtime\n",
    "%pip -q install -U keras keras-hub tensorflow tensorflow-text datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6035ef-078b-4ae3-8695-7e0d135cd51e",
   "metadata": {
    "id": "bb6035ef-078b-4ae3-8695-7e0d135cd51e"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras_hub as kh\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset, Features, Value, ClassLabel\n",
    "\n",
    "from keras import mixed_precision                    # generally faster\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9307f-eb34-49e7-84e8-ed373dbd8ef3",
   "metadata": {
    "id": "50a9307f-eb34-49e7-84e8-ed373dbd8ef3"
   },
   "source": [
    "### Here is where you can set global hyperparameters for this homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "189c9bbc-c634-417f-909b-ccc4d5945c76",
   "metadata": {
    "id": "189c9bbc-c634-417f-909b-ccc4d5945c76"
   },
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "SEED        = 42\n",
    "MAX_LEN     = 128\n",
    "EPOCHS      = 3\n",
    "BATCH       = 32\n",
    "EVAL_BATCH  = 64\n",
    "SUBSET_FRAC = 0.25   # <-- 0.25 to train and test on 25% of whole dataset during development;  set to 1.0 for full dataset\n",
    "\n",
    "keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d68ff-94e2-402a-8bd3-fef3cba9e7bf",
   "metadata": {
    "id": "d33d68ff-94e2-402a-8bd3-fef3cba9e7bf"
   },
   "source": [
    "### Load and Preprocess the IMDB Movie Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c3b6bd-ddc3-4c75-b0ba-8b09d2f42a96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59c3b6bd-ddc3-4c75-b0ba-8b09d2f42a96",
    "outputId": "fb3c56dd-59c5-4878-b426-6ed894841bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool after SUBSET_FRAC=0.25: 12500 (of 50000)\n",
      "Train: (8750, [4375, 4375])  Val: (1250, [625, 625])  Test: (2500, [1250, 1250])\n"
     ]
    }
   ],
   "source": [
    "# ---- Load IMDb (raw), join train+test ----\n",
    "imdb   = load_dataset(\"imdb\")\n",
    "texts  = list(imdb[\"train\"][\"text\"]) + list(imdb[\"test\"][\"text\"])\n",
    "labels = np.array(list(imdb[\"train\"][\"label\"]) + list(imdb[\"test\"][\"label\"]), dtype=\"int32\")\n",
    "\n",
    "# ---- Build DS with explicit features (label=ClassLabel) ----\n",
    "features = Features({\"text\": Value(\"string\"),\n",
    "                     \"label\": ClassLabel(num_classes=2, names=[\"NEG\",\"POS\"])})\n",
    "all_ds = Dataset.from_dict({\"text\": texts, \"label\": labels.tolist()}, features=features)\n",
    "\n",
    "# ---- Optional: take a stratified subset of the FULL dataset ----\n",
    "if 0.0 < SUBSET_FRAC < 1.0:\n",
    "    sub = all_ds.train_test_split(train_size=SUBSET_FRAC, seed=SEED, stratify_by_column=\"label\")\n",
    "    ds_pool = sub[\"train\"]\n",
    "else:\n",
    "    ds_pool = all_ds\n",
    "\n",
    "# ---- Stratified 80/10/10 split on the (possibly smaller) pool ----\n",
    "# First: 80/20 train+val pool / test\n",
    "splits = ds_pool.train_test_split(test_size=0.20, seed=SEED, stratify_by_column=\"label\")\n",
    "train_val_pool, test_ds = splits[\"train\"], splits[\"test\"]\n",
    "# Then: carve 10% of full (i.e., 0.125 of the 80% pool) as validation\n",
    "splits2 = train_val_pool.train_test_split(test_size=0.125, seed=SEED, stratify_by_column=\"label\")\n",
    "train_ds, val_ds = splits2[\"train\"], splits2[\"test\"]\n",
    "\n",
    "# ---- Numpy arrays for Keras fit/predict ----\n",
    "X_tr = np.array(train_ds[\"text\"], dtype=object); y_tr = np.array(train_ds[\"label\"], dtype=\"int32\")\n",
    "X_va = np.array(val_ds[\"text\"],   dtype=object); y_va = np.array(val_ds[\"label\"],   dtype=\"int32\")\n",
    "X_te = np.array(test_ds[\"text\"],  dtype=object); y_te = np.array(test_ds[\"label\"],  dtype=\"int32\")\n",
    "\n",
    "# ---- Quick summary ----\n",
    "def _counts(ds):\n",
    "    arr = np.array(ds[\"label\"], dtype=int)\n",
    "    return len(arr), np.bincount(arr, minlength=2).tolist()\n",
    "print(f\"Pool after SUBSET_FRAC={SUBSET_FRAC}: {len(ds_pool)} (of {len(all_ds)})\")\n",
    "print(\"Train:\", _counts(train_ds), \" Val:\", _counts(val_ds), \" Test:\", _counts(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3cf44-614f-4b4b-801a-8865adf1ded3",
   "metadata": {
    "id": "c6e3cf44-614f-4b4b-801a-8865adf1ded3"
   },
   "source": [
    "### Build and train a baseline Distil-Bert Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4814b089-9299-4828-865a-81ae45bb2bb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4814b089-9299-4828-865a-81ae45bb2bb5",
    "outputId": "d7329e24-f66a-43ca-88b1-067feeec24c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 226ms/step - acc: 0.7824 - loss: 0.4530 - val_acc: 0.8376 - val_loss: 0.3448\n",
      "Epoch 2/3\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - acc: 0.8787 - loss: 0.2897 - val_acc: 0.8584 - val_loss: 0.3400\n",
      "Epoch 3/3\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - acc: 0.9160 - loss: 0.2207 - val_acc: 0.8592 - val_loss: 0.3555\n",
      "\n",
      "Validation acc (best epoch): 0.858\n",
      "\n",
      "Test accuracy: 0.855   Test F1: 0.851\n",
      "\n",
      "Confusion matrix:\n",
      " [[1098  152]\n",
      " [ 211 1039]]\n",
      "\n",
      "Elapsed time: 00:02:24\n"
     ]
    }
   ],
   "source": [
    "# ---- Keras Hub preprocessor + classifier ----\n",
    "preproc = kh.models.DistilBertTextClassifierPreprocessor.from_preset(\n",
    "    \"distil_bert_base_en_uncased\", sequence_length=MAX_LEN\n",
    ")\n",
    "model = kh.models.DistilBertTextClassifier.from_preset(\n",
    "    \"distil_bert_base_en_uncased\", num_classes=2, preprocessor=preproc\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# ---- Train with early stopping (restore best val weights) ----\n",
    "cb = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)]\n",
    "history = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    validation_data=(X_va, y_va),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    callbacks=cb,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# ---- Evaluate (accuracy + F1 via `evaluate`) ----\n",
    "logits = model.predict(X_te, batch_size=EVAL_BATCH, verbose=0)\n",
    "y_pred = logits.argmax(axis=-1)\n",
    "\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric  = evaluate.load(\"f1\")\n",
    "acc = acc_metric.compute(predictions=y_pred, references=y_te)[\"accuracy\"]\n",
    "f1  = f1_metric.compute(predictions=y_pred, references=y_te)[\"f1\"]\n",
    "\n",
    "# Tiny confusion matrix helper (no sklearn needed)\n",
    "def confusion_matrix_np(y_true, y_pred, num_classes=2):\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t, p] += 1\n",
    "    return cm\n",
    "\n",
    "print(f\"\\nValidation acc (best epoch): {history.history['val_acc'][np.argmin(history.history['val_loss'])]:.3f}\")\n",
    "print(f\"\\nTest accuracy: {acc:.3f}   Test F1: {f1:.3f}\")\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix_np(y_te, y_pred))\n",
    "\n",
    "end = time.time() - start\n",
    "print(\"\\nElapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe4979-adac-4d73-aa57-a91cd0b2ad34",
   "metadata": {
    "id": "d2fe4979-adac-4d73-aa57-a91cd0b2ad34"
   },
   "source": [
    "# Problem 1 — Mini sweep: context length × learning rate (6 runs)\n",
    "\n",
    "In this problem we'll see how much **context length** (`MAX_LEN`) helps, and how sensitive fine-tuning is to **learning rate**—without running a huge grid.\n",
    "\n",
    "## Setup (keep these fixed)\n",
    "\n",
    "* `SUBSET_FRAC = 0.25`               # use only this percentage of the whole dataset\n",
    "* `EPOCHS = 3`\n",
    "* `BATCH = 32` (but see note for 256 below)\n",
    "* **EarlyStopping** with `restore_best_weights=True`\n",
    "* Same random `SEED` for all runs\n",
    "* Same data split for all runs (don’t reshuffle between runs)\n",
    "\n",
    "### Run these 6 configurations\n",
    "\n",
    "**For each** `MAX_LEN ∈ {128, 256, 512}`, try **two** learning rates:\n",
    "\n",
    "* **MAX_LEN = 128**\n",
    "\n",
    "  * `(LR = 2e-5, BATCH = 32)` – healthy default for shorter contexts.\n",
    "  * `(LR = 1e-5, BATCH = 32)` – conservative LR; often a touch stabler.\n",
    "\n",
    "* **MAX_LEN = 256**\n",
    "\n",
    "  * `(LR = 1e-5, BATCH = 16)` – longer context → lower batch.\n",
    "  * `(LR = 7.5e-6, BATCH = 16)` – even steadier if loss is noisy.\n",
    "\n",
    "* **MAX_LEN = 512**  *(heavier quadratic attention cost)*\n",
    "\n",
    "  * `(LR = 7.5e-6, BATCH = 8)` – safe starting point.\n",
    "  * `(LR = 5e-6, BATCH = 8)` – extra caution for stability.\n",
    "\n",
    "**If you hit an Out Of Memory error:**\n",
    "\n",
    "* At **256** with `BATCH = 16`, drop to `BATCH = 8`.\n",
    "* At **512** with `BATCH = 8`, drop to `BATCH = 4`.\n",
    "\n",
    "\n",
    "Then answer the graded questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd105932-3dc1-47e5-9b4a-90f4e9206143",
   "metadata": {
    "id": "bd105932-3dc1-47e5-9b4a-90f4e9206143"
   },
   "outputs": [],
   "source": [
    "# Your code here; add as many cells as you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa6ea8a-6482-4c7b-81ba-aadbb3bfe564",
   "metadata": {
    "id": "1aa6ea8a-6482-4c7b-81ba-aadbb3bfe564"
   },
   "source": [
    "### Graded Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a67d26c5-8294-438a-b29f-6a091180a1f8",
   "metadata": {
    "id": "a67d26c5-8294-438a-b29f-6a091180a1f8"
   },
   "outputs": [],
   "source": [
    "# Set a1a to the validation accuracy at min validation loss for your best configuration found in this problem\n",
    "\n",
    "a1a = 0.0             # Replace 0.0 with your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd1c33c-4761-4954-a04d-e4e4def945ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dd1c33c-4761-4954-a04d-e4e4def945ab",
    "outputId": "d022b7e7-1c60-44f8-fbe9-c3221ead18ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1a = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Graded Answer\n",
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a1a = {a1a:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d2a89-301d-4f8d-9236-f88a1bc023ca",
   "metadata": {
    "id": "d46d2a89-301d-4f8d-9236-f88a1bc023ca"
   },
   "source": [
    "#### Question a1b:\n",
    "\n",
    "* Does **more context** (128 → 256 → 512) consistently help?\n",
    "* How much effect did the learning rate have on the validation accuracy?\n",
    "\n",
    "\n",
    "#### Your Answer Here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef49299-6f39-4b66-9e16-52417f3f917f",
   "metadata": {
    "id": "6ef49299-6f39-4b66-9e16-52417f3f917f"
   },
   "source": [
    "## Problem 2 — How much data is enough?\n",
    "\n",
    "In this problem, you’ll investigate how model performance scales with dataset size.\n",
    "\n",
    "**Setup.**\n",
    "Use the best `MAX_LEN` and `LR` values you found in **Problem 1**.\n",
    "\n",
    "**What to do:**\n",
    "\n",
    "1. For each value of `SUBSET_FRAC ∈ {0.25, 0.50, 0.75, 1.00}`, train your model once and observe the displayed performance metrics.\n",
    "2. Answer the discussion question below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b9ebc5-809a-4e13-a4c6-1325b0d9a171",
   "metadata": {
    "id": "82b9ebc5-809a-4e13-a4c6-1325b0d9a171"
   },
   "outputs": [],
   "source": [
    "# Your code here; add as many cells as you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43868b2d-3a63-4422-a11c-b0eb7ada89a7",
   "metadata": {
    "id": "43868b2d-3a63-4422-a11c-b0eb7ada89a7"
   },
   "source": [
    "### Graded Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00abc6af-69f5-494e-8349-9e0ebf115e42",
   "metadata": {
    "id": "00abc6af-69f5-494e-8349-9e0ebf115e42"
   },
   "outputs": [],
   "source": [
    "# Set a2a to the validation accuracy at min validation loss for your best configuration found in this problem\n",
    "# (Yes, it is probably at 1.0!)\n",
    "\n",
    "a2a = 0.0             # Replace 0.0 with your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a4afa0b-5e7d-4ba1-8bb5-8d5229aef4fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a4afa0b-5e7d-4ba1-8bb5-8d5229aef4fd",
    "outputId": "f5632a5e-0328-425f-8d6c-b06020dd00dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2a = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Graded Answer\n",
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a2a = {a2a:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba14dbe-08bd-4a03-ad90-2e2046a9ac78",
   "metadata": {
    "id": "5ba14dbe-08bd-4a03-ad90-2e2046a9ac78"
   },
   "source": [
    "#### Question a2b:\n",
    "\n",
    "Summarize what you observed as dataset size increased. Given that validation metrics are typically reliable to only about two decimal places, do the performance gains justify using the entire dataset? What trade-offs between accuracy and computation time did you notice?\n",
    "\n",
    "#### Your Answer Here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c9212-dde0-4a33-b926-70ef9dddd1be",
   "metadata": {
    "id": "1e8c9212-dde0-4a33-b926-70ef9dddd1be"
   },
   "source": [
    "# Problem 3 — Model swap: speed vs. accuracy (why: capacity matters)\n",
    "\n",
    "In this problem we will compare encoder-only backbones of different sizes.\n",
    "\n",
    "**Setup.** Keep the best `MAX_LEN`, `LR`, and `SUBSET_FRAC` from Problems 1–2. Only change the model/preset:\n",
    "\n",
    "* **DistilBERT** (current baseline)\n",
    "* **BERT-base** (larger/usually stronger)\n",
    "\n",
    "**How to switch (two lines each).**\n",
    "\n",
    "* DistilBERT:\n",
    "\n",
    "  ```python\n",
    "  preproc = kh.models.DistilBertTextClassifierPreprocessor.from_preset(\"distil_bert_base_en_uncased\", sequence_length=MAX_LEN)\n",
    "  model  = kh.models.DistilBertTextClassifier.from_preset(\"distil_bert_base_en_uncased\", num_classes=2, preprocessor=preproc)\n",
    "  ```\n",
    "\n",
    "* BERT-base:\n",
    "\n",
    "  ```python\n",
    "  preproc = kh.models.BertTextClassifierPreprocessor.from_preset(\"bert_base_en_uncased\", sequence_length=MAX_LEN)\n",
    "  model  = kh.models.BertTextClassifier.from_preset(\"bert_base_en_uncased\", num_classes=2, preprocessor=preproc)\n",
    "  ```\n",
    "\n",
    "**What to do.**\n",
    "\n",
    "1. Train/evaluate each model once with identical settings.\n",
    "2. Observe the performance metrics for each.\n",
    "3. Answer the graded questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce5521c-e487-4ee6-8ce8-a93a5231eec9",
   "metadata": {
    "id": "0ce5521c-e487-4ee6-8ce8-a93a5231eec9"
   },
   "outputs": [],
   "source": [
    "# Your code here; add as many cells as you wish\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f3698-11a9-4451-a53e-a2e92e18421a",
   "metadata": {
    "id": "147f3698-11a9-4451-a53e-a2e92e18421a"
   },
   "source": [
    "### Graded Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18d7925a-2494-4689-b329-0b625827a0a8",
   "metadata": {
    "id": "18d7925a-2494-4689-b329-0b625827a0a8"
   },
   "outputs": [],
   "source": [
    "# Set a1a to the validation accuracy at min validation loss for your best model found in this problem\n",
    "\n",
    "a3a = 0.0             # Replace 0.0 with your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deec774a-2360-494d-9e2f-989164095a79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deec774a-2360-494d-9e2f-989164095a79",
    "outputId": "ff6f074c-b7bf-47d4-93f3-148c281f8d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3a = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Graded Answer\n",
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a3a = {a3a:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b6ce4d-28a7-4414-8d1c-114a6bc5fa5f",
   "metadata": {
    "id": "58b6ce4d-28a7-4414-8d1c-114a6bc5fa5f"
   },
   "source": [
    "#### Question a3b:\n",
    "\n",
    "**Answer briefly.**\n",
    "\n",
    "* Which model gives the best **accuracy/F1**?\n",
    "* Which is **fastest** per epoch?\n",
    "* Given limited development time or compute resources, which model is the best **overall choice** and why?\n",
    "\n",
    "#### Your Answer Here:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
