{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone Two\n",
    "\n",
    "**Data Preparation and Model Exploration**\n",
    "**Due:** Midnight on November 16th with usual 2-hour grace period — **worth 100 points**\n",
    "\n",
    "**Note: No late assignments accepted, we need the time to grade them!**\n",
    "\n",
    "In Milestone 1, your team selected a dataset (Food-101 or HuffPost), analyzed its structure, and identified key challenges and evaluation metrics.\n",
    "In this milestone, you will carry out those plans: prepare the data, train three models of increasing sophistication, and evaluate their results using Keras and TensorFlow.\n",
    "You will finish with a comparative discussion of model performance and trade-offs.\n",
    "\n",
    "\n",
    "### Submission Guidelines\n",
    "\n",
    "* Submit one Jupyter notebook per team through the team leader’s Gradescope account. **Include all team members names at the top of the notebook.** \n",
    "* Include all code, plots, and answers inline below.\n",
    "* Ensure reproducibility by setting random seeds and listing all hyperparameters.\n",
    "* Document any AI tools used, as required by the CDS policy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 – Data Preparation and Splits (20 pts)\n",
    "\n",
    "### Goals\n",
    "\n",
    "Implement the **data preparation and preprocessing steps** that you proposed in **Milestone 1**. You’ll clean, normalize, and split your data so that it’s ready for modeling and reproducible fine-tuning.\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Load your chosen dataset**\n",
    "\n",
    "   * Use `datasets.load_dataset()` from **Hugging Face** to load **Food-101** or **HuffPost**.\n",
    "   * Display basic information (e.g., number of samples, feature names, example entries).\n",
    "\n",
    "2. **Apply cleaning and normalization**\n",
    "\n",
    "   * **Images:**\n",
    "\n",
    "     * Ensure all images are in RGB format.\n",
    "     * Resize or crop to a consistent shape (e.g., `224 × 224`).\n",
    "     * Drop or fix any corrupted files.\n",
    "   * **Text:**\n",
    "\n",
    "     * Concatenate headline + summary (for HuffPost).\n",
    "     * Strip whitespace, convert to lowercase if appropriate, and remove empty samples.\n",
    "     * Optionally remove duplicates or extremely short entries.\n",
    "\n",
    "3. **Standardize or tokenize the inputs**\n",
    "\n",
    "   * **Images:**\n",
    "\n",
    "     * Normalize pixel values (e.g., divide by 255.0).\n",
    "     * Define a minimal augmentation pipeline (e.g., random flip, crop, or rotation).\n",
    "   * **Text:**\n",
    "\n",
    "     * Create a tokenizer or `TextVectorization` layer.\n",
    "     * Set a target `max_length` based on your analysis from Milestone 1 (e.g., 95th percentile).\n",
    "     * Apply padding/truncation and build tensors for input + labels.\n",
    "\n",
    "4. **Handle dataset-specific challenges**\n",
    "\n",
    "   * If you identified **class imbalance**, compute label counts and, if needed, create a dictionary of `class_weights`.\n",
    "   * If you noted **length or size variance**, verify that your truncation or resizing works as intended.\n",
    "   * If you planned **noise filtering**, include the cleaning step and briefly explain your criteria (e.g., remove items with missing text or unreadable images).\n",
    "\n",
    "5. **Create reproducible splits**\n",
    "\n",
    "   * Split your cleaned dataset into **train**, **validation**, and **test** subsets (e.g., 80 / 10 / 10).\n",
    "   * Use a fixed random seed for reproducibility (`random_seed = 42`).\n",
    "   * Use **stratified splits**  (e.g., with `train_test_split` and `stratify = labels`).\n",
    "   * Display the size of each subset.\n",
    "\n",
    "6. **Document your pipeline**\n",
    "\n",
    "   * Summarize your preprocessing steps clearly in Markdown or code comments.\n",
    "   * Save or display a few representative examples after preprocessing to confirm the transformations are correct.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here; add as many cells as you need but make it clear what the structure is. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "For each question, answer thoroughly but concisely, in a short paragraph, longer or shorter as needed. Code for exploring the concepts should go in the previous cell\n",
    "as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Loading and Cleaning:**\n",
    "   Describe how you loaded your dataset and the key cleaning steps you implemented (e.g., handling missing data, normalizing formats, or removing duplicates).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Preprocessing and Standardization:**\n",
    "   Summarize your preprocessing pipeline. Include any normalization, tokenization, resizing, or augmentation steps, and explain why each was necessary for your dataset.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Train/Validation/Test Splits:**\n",
    "   Explain how you divided your data into subsets, including the split ratios, random seed, and any stratification or leakage checks you used to verify correctness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Class Distribution and Balance:**\n",
    "   Report your label counts and describe any class imbalances you observed. If applicable, explain how you addressed them (e.g., weighting, oversampling, or data augmentation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 – Baseline Model (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Build and train a **simple, fully functional baseline model** to establish a reference level of performance for your dataset.\n",
    "This baseline will help you evaluate whether later architectures and fine-tuning steps actually improve results.\n",
    "\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Construct a baseline model**\n",
    "\n",
    "   * **Images:**\n",
    "     Use a compact CNN, for example\n",
    "     `Conv2D → MaxPooling → Flatten → Dense → Softmax`.\n",
    "   * **Text:**\n",
    "     Use a small embedding-based classifier such as\n",
    "     `Embedding → GlobalAveragePooling → Dense → Softmax`.\n",
    "   * Keep the model small enough to train in minutes on Colab.\n",
    "\n",
    "2. **Compile the model**\n",
    "\n",
    "   * Optimizer: `Adam` or `AdamW`.\n",
    "   * Loss: `categorical_crossentropy` (for multi-class).\n",
    "   * Metrics: at least `accuracy`; add `F1` if appropriate.\n",
    "\n",
    "3. **Train and validate**\n",
    "\n",
    "   * Use **early stopping** on validation loss with the default patience value (e.g., 5 epochs).\n",
    "   * Record number of epochs trained and total runtime.\n",
    "\n",
    "4. **Visualize results**\n",
    "\n",
    "   * Plot **training vs. validation accuracy and loss**.\n",
    "   * Carefully observe: does the model underfit, overfit, or generalize reasonably?\n",
    "\n",
    "5. **Report baseline performance**\n",
    "\n",
    "   * The most important metric is the **validation accuracy at the epoch of minimum validation loss**; this serves as your **benchmark** for all later experiments in this milestone.\n",
    "   * Evaluate on the **test set** and record final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here; add as many cells as you need but make it clear what the structure is. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "1. **Model Architecture:**\n",
    "   Describe your baseline model and justify why this structure suits your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Training Behavior:**\n",
    "   Summarize the model’s training and validation curves. What trends did you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. **Baseline Metrics:**\n",
    "   Report validation and test metrics. What does this performance tell you about dataset difficulty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  4. **Reflection:**\n",
    "   What are the main limitations of your baseline? Which specific improvements (depth, regularization, pretraining) would you try next?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 – Custom (Original) Model (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Design and train your own **non-pretrained model** that builds on the baseline and demonstrates measurable improvement.\n",
    "This problem focuses on experimentation: apply one or two clear architectural changes, observe their effects, and evaluate how they influence learning behavior.\n",
    "\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Modify or extend your baseline architecture**\n",
    "\n",
    "   * Begin from your baseline model and introduce one or more meaningful adjustments such as:\n",
    "\n",
    "     * Adding **dropout** or **batch normalization** for regularization.\n",
    "     * Increasing **depth** (extra convolutional or dense layers).\n",
    "     * Using **residual connections** (for CNNs) or **bidirectional LSTMs/GRUs** (for text).\n",
    "     * Trying alternative activations like `ReLU`, `LeakyReLU`, or `GELU`.\n",
    "   * Keep the model small enough to train comfortably on your chosen platform (e.g., Colab)\n",
    "\n",
    "2. **Observe what specific limitations you want to address**\n",
    "\n",
    "   * Identify whether the baseline showed **underfitting**, **overfitting**, or **slow convergence**, and design your modification to target that behavior.\n",
    "   * Make brief notes (in comments or Markdown) describing what you expect the change to influence.\n",
    "\n",
    "3. **Train and evaluate under the same conditions**\n",
    "\n",
    "   * Use the **same data splits**, **random seed**, and **metrics** as in Problem 2.\n",
    "   * Apply **early stopping** on validation loss.\n",
    "   * Track and visualize training/validation accuracy and loss over epochs.\n",
    "\n",
    "4. **Compare outcomes to the baseline**\n",
    "\n",
    "   * Observe differences in convergence speed, stability, and validation/test performance.\n",
    "   * Note whether your modification improved generalization or simply increased model capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "1. **Model Design:**\n",
    "   Describe the architectural changes you introduced compare with your baseline model and what motivated them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Training Results:**\n",
    "   Present key validation and test metrics. Did your modifications improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Interpretation:**\n",
    "   Discuss what worked, what didn’t, and how your results relate to baseline behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Reflection:**\n",
    "   What insights did this experiment give you about model complexity, regularization, or optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 – Pretrained Model (Transfer Learning) (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Apply **transfer learning** to see how pretrained knowledge improves accuracy, convergence speed, and generalization.\n",
    "This experiment will help you compare the benefits and trade-offs of using pretrained models versus those trained from scratch.\n",
    "\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Select a pretrained architecture**\n",
    "\n",
    "   * **Images:** choose from `MobileNetV2`, `ResNet50`, `EfficientNetB0`, or a similar model in `tf.keras.applications`.\n",
    "   * **Text:** choose from `BERT`, `DistilBERT`, `RoBERTa`, or another Transformer available in `transformers`.\n",
    "\n",
    "2. **Adapt the model for your dataset**\n",
    "\n",
    "   * Use the correct **preprocessing function** and **input shape** required by your chosen model.\n",
    "   * Replace the top layer with your own **classification head** (e.g., `Dense(num_classes, activation='softmax')`).\n",
    "\n",
    "3. **Apply transfer learning**\n",
    "\n",
    "   * Choose an appropriate **training strategy** for your pretrained model. Options include:\n",
    "\n",
    "     * **Freezing** the pretrained base and training only a new classification head.\n",
    "     * **Partially fine-tuning** selected upper layers of the base model.\n",
    "     * **Full fine-tuning** (all layers trainable) with a reduced learning rate.\n",
    "   * Adjust your learning rate schedule to match your strategy (e.g., smaller LR for fine-tuning).\n",
    "   * Observe how your chosen approach affects **validation loss**, **training time**, and **model stability**.\n",
    "\n",
    "4. **Train and evaluate under consistent conditions**\n",
    "\n",
    "   * Use the same **splits**, **metrics**, and **evaluation protocol** as in earlier problems.\n",
    "   * Record training duration, validation/test performance, and any resource constraints (GPU memory, runtime).\n",
    "\n",
    "5. **Compare and analyze**\n",
    "\n",
    "   * Observe how transfer learning changes both **performance** and **efficiency** relative to your baseline and custom models.\n",
    "   * Identify whether the pretrained model improved accuracy, sped up convergence, or introduced new challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "1. **Model Choice:** Which pretrained architecture did you select, and what motivated that choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Fine-Tuning Plan:** Describe your fine-tuning strategy and why you chose it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Performance:** Report key metrics and compare them with your baseline and custom models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Computation:** Summarize how training time, memory use, or convergence speed differed from the previous two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 – Comparative Evaluation and Discussion (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Compare your **baseline**, **custom**, and **pretrained** models to evaluate how design choices affected performance, efficiency, and generalization.\n",
    "This problem brings your work together and encourages reflection on what you’ve learned about model behavior and trade-offs.\n",
    "\n",
    "**Note** that this is not your final report, and you will continue to refine your results for the final report. \n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Compile key results**\n",
    "\n",
    "   * Gather your main metrics for each model: **accuracy**, **F1**, **training time**, and **parameter count or model size**.\n",
    "   * Ensure all numbers come from the same evaluation protocol and test set.\n",
    "\n",
    "2. **Visualize the comparison**\n",
    "\n",
    "   * Present results in a **single, well-organized chart or table**.\n",
    "   * Optionally, include training curves or confusion matrices for additional insight.\n",
    "\n",
    "3. **Analyze comparative performance**\n",
    "\n",
    "   * Observe which model performed best by your chosen metric(s).\n",
    "   * Note patterns in efficiency (training speed, memory use) and stability (validation variance).\n",
    "\n",
    "4. **Inspect model behavior**\n",
    "\n",
    "   * Look at a few representative misclassifications or difficult examples.\n",
    "   * Identify whether certain classes or inputs consistently caused errors.\n",
    "\n",
    "5. **Plan forward improvements**\n",
    "\n",
    "   * In the final report, you will use your best model and conclude your investigation of your dataset. Based on your observations, decide on a model and next steps for refining your approach in the final project (e.g., regularization, data augmentation, model scaling, or more targeted fine-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (4 pts each)\n",
    "\n",
    "1. **Summary Table and Performance Analysis:** Present a clear quantitative comparison of all three models. Which model achieved the best overall results, and what factors contributed to its success?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Trade-Offs:** Discuss how complexity, accuracy, and efficiency balanced across your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Error Patterns:** Describe the types of examples or classes that remained challenging for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Next Steps:** Based on these findings, decide on a model to go forward with and outline your plan for improving that model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Question: Describe what use you made of generative AI tools in preparing this Milestone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Question: Your answer here:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
